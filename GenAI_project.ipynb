{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Importing required packages"
      ],
      "metadata": {
        "id": "Eb8xit1C_iDv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrIB-XS5GVt-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Embedding, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading csv file"
      ],
      "metadata": {
        "id": "GNBHUGLu_lx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "f=files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "gD06OwmYK6k_",
        "outputId": "549ffae8-cea6-445b-944a-28815cd69068"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1b70a9f1-2768-49a0-ad2f-b78702534564\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1b70a9f1-2768-49a0-ad2f-b78702534564\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving creative_writing2.csv to creative_writing2.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('creative_writing2.csv')"
      ],
      "metadata": {
        "id": "jzfUfAaEGtZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dropping Null values"
      ],
      "metadata": {
        "id": "x495PUzWAh8X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "7ZnwWgrmHkLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating the corpus"
      ],
      "metadata": {
        "id": "UgtZ2tt8Akam"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [(prompt, creative_writing) for prompt, creative_writing in zip(df['prompt'], df['creative_writing'])]"
      ],
      "metadata": {
        "id": "qfOyJsj7HSPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fitting the tokenizer in the corpus"
      ],
      "metadata": {
        "id": "C4SSET7BAmi_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([row[1] for row in corpus])\n",
        "total_words = len(tokenizer.word_index) + 1"
      ],
      "metadata": {
        "id": "ZUw7xr9UHW-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Creating Input Sequences for Neural Network Training"
      ],
      "metadata": {
        "id": "oXesihpwADpv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = []\n",
        "for _, creative_writing in corpus:\n",
        "    token_list = tokenizer.texts_to_sequences([creative_writing])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        input_sequences.append(n_gram_sequence)"
      ],
      "metadata": {
        "id": "yDRchkTXHnjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Padding Input Sequences for Uniform Length"
      ],
      "metadata": {
        "id": "nolqX4xsAJH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))"
      ],
      "metadata": {
        "id": "E335le7hHtg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting Input and Target Sequences"
      ],
      "metadata": {
        "id": "LNFVZChtAL9W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = input_sequences[:,:-1],input_sequences[:,-1]"
      ],
      "metadata": {
        "id": "3NqenzvUHxgy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Training a Bidirectional LSTM Model for Text Generation"
      ],
      "metadata": {
        "id": "lnpeYFF2AN-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 50, input_length=max_sequence_len-1))\n",
        "model.add(Bidirectional(LSTM(150)))\n",
        "model.add(Dense(total_words, activation='softmax'))"
      ],
      "metadata": {
        "id": "CoWjPkijH1pJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "P-0yd-KcH5Pt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, y, epochs=100, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJxbtr1bH-y9",
        "outputId": "32fe2eeb-67aa-4351-8ab3-59b66688ffbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "199/199 [==============================] - 26s 107ms/step - loss: 6.3525 - accuracy: 0.0943\n",
            "Epoch 2/100\n",
            "199/199 [==============================] - 22s 110ms/step - loss: 5.7149 - accuracy: 0.1322\n",
            "Epoch 3/100\n",
            "199/199 [==============================] - 22s 112ms/step - loss: 5.4187 - accuracy: 0.1692\n",
            "Epoch 4/100\n",
            "199/199 [==============================] - 22s 110ms/step - loss: 5.1084 - accuracy: 0.1940\n",
            "Epoch 5/100\n",
            "199/199 [==============================] - 22s 111ms/step - loss: 4.7948 - accuracy: 0.2088\n",
            "Epoch 6/100\n",
            "199/199 [==============================] - 22s 108ms/step - loss: 4.5023 - accuracy: 0.2257\n",
            "Epoch 7/100\n",
            "199/199 [==============================] - 22s 108ms/step - loss: 4.2300 - accuracy: 0.2425\n",
            "Epoch 8/100\n",
            "199/199 [==============================] - 21s 104ms/step - loss: 3.9803 - accuracy: 0.2593\n",
            "Epoch 9/100\n",
            "199/199 [==============================] - 22s 108ms/step - loss: 3.7418 - accuracy: 0.2758\n",
            "Epoch 10/100\n",
            "199/199 [==============================] - 21s 108ms/step - loss: 3.5223 - accuracy: 0.2963\n",
            "Epoch 11/100\n",
            "199/199 [==============================] - 21s 108ms/step - loss: 3.3090 - accuracy: 0.3197\n",
            "Epoch 12/100\n",
            "199/199 [==============================] - 22s 109ms/step - loss: 3.1083 - accuracy: 0.3438\n",
            "Epoch 13/100\n",
            "199/199 [==============================] - 22s 109ms/step - loss: 2.9177 - accuracy: 0.3712\n",
            "Epoch 14/100\n",
            "199/199 [==============================] - 21s 104ms/step - loss: 2.7308 - accuracy: 0.4050\n",
            "Epoch 15/100\n",
            "199/199 [==============================] - 22s 110ms/step - loss: 2.5529 - accuracy: 0.4454\n",
            "Epoch 16/100\n",
            "199/199 [==============================] - 22s 110ms/step - loss: 2.3720 - accuracy: 0.4906\n",
            "Epoch 17/100\n",
            "199/199 [==============================] - 21s 107ms/step - loss: 2.2127 - accuracy: 0.5252\n",
            "Epoch 18/100\n",
            "199/199 [==============================] - 21s 108ms/step - loss: 2.0486 - accuracy: 0.5654\n",
            "Epoch 19/100\n",
            "199/199 [==============================] - 21s 108ms/step - loss: 1.8993 - accuracy: 0.5936\n",
            "Epoch 20/100\n",
            "199/199 [==============================] - 21s 104ms/step - loss: 1.7518 - accuracy: 0.6330\n",
            "Epoch 21/100\n",
            "199/199 [==============================] - 21s 108ms/step - loss: 1.6145 - accuracy: 0.6691\n",
            "Epoch 22/100\n",
            "199/199 [==============================] - 21s 107ms/step - loss: 1.4786 - accuracy: 0.7045\n",
            "Epoch 23/100\n",
            "199/199 [==============================] - 22s 109ms/step - loss: 1.3609 - accuracy: 0.7289\n",
            "Epoch 24/100\n",
            "199/199 [==============================] - 21s 107ms/step - loss: 1.2441 - accuracy: 0.7612\n",
            "Epoch 25/100\n",
            "199/199 [==============================] - 21s 105ms/step - loss: 1.1393 - accuracy: 0.7809\n",
            "Epoch 26/100\n",
            "199/199 [==============================] - 21s 105ms/step - loss: 1.0416 - accuracy: 0.8085\n",
            "Epoch 27/100\n",
            "199/199 [==============================] - 21s 108ms/step - loss: 0.9486 - accuracy: 0.8338\n",
            "Epoch 28/100\n",
            "199/199 [==============================] - 21s 107ms/step - loss: 0.8646 - accuracy: 0.8500\n",
            "Epoch 29/100\n",
            "199/199 [==============================] - 22s 109ms/step - loss: 0.7850 - accuracy: 0.8633\n",
            "Epoch 30/100\n",
            "199/199 [==============================] - 22s 109ms/step - loss: 0.7183 - accuracy: 0.8819\n",
            "Epoch 31/100\n",
            "199/199 [==============================] - 21s 104ms/step - loss: 0.6462 - accuracy: 0.8956\n",
            "Epoch 32/100\n",
            "199/199 [==============================] - 21s 107ms/step - loss: 0.5856 - accuracy: 0.9073\n",
            "Epoch 33/100\n",
            "199/199 [==============================] - 21s 108ms/step - loss: 0.5366 - accuracy: 0.9180\n",
            "Epoch 34/100\n",
            "199/199 [==============================] - 21s 108ms/step - loss: 0.4849 - accuracy: 0.9248\n",
            "Epoch 35/100\n",
            "199/199 [==============================] - 22s 109ms/step - loss: 0.4434 - accuracy: 0.9360\n",
            "Epoch 36/100\n",
            "199/199 [==============================] - 22s 108ms/step - loss: 0.4010 - accuracy: 0.9440\n",
            "Epoch 37/100\n",
            "199/199 [==============================] - 21s 107ms/step - loss: 0.3684 - accuracy: 0.9478\n",
            "Epoch 38/100\n",
            "199/199 [==============================] - 21s 107ms/step - loss: 0.3375 - accuracy: 0.9499\n",
            "Epoch 39/100\n",
            "199/199 [==============================] - 22s 109ms/step - loss: 0.3085 - accuracy: 0.9554\n",
            "Epoch 40/100\n",
            "199/199 [==============================] - 22s 109ms/step - loss: 0.2814 - accuracy: 0.9579\n",
            "Epoch 41/100\n",
            "199/199 [==============================] - 21s 107ms/step - loss: 0.2664 - accuracy: 0.9590\n",
            "Epoch 42/100\n",
            "199/199 [==============================] - 22s 110ms/step - loss: 0.2359 - accuracy: 0.9622\n",
            "Epoch 43/100\n",
            "199/199 [==============================] - 22s 110ms/step - loss: 0.2203 - accuracy: 0.9625\n",
            "Epoch 44/100\n",
            "199/199 [==============================] - 21s 105ms/step - loss: 0.2075 - accuracy: 0.9651\n",
            "Epoch 45/100\n",
            "199/199 [==============================] - 21s 108ms/step - loss: 0.1928 - accuracy: 0.9656\n",
            "Epoch 46/100\n",
            "199/199 [==============================] - 21s 107ms/step - loss: 0.1769 - accuracy: 0.9678\n",
            "Epoch 47/100\n",
            "199/199 [==============================] - 21s 106ms/step - loss: 0.1676 - accuracy: 0.9691\n",
            "Epoch 48/100\n",
            "199/199 [==============================] - 21s 107ms/step - loss: 0.1600 - accuracy: 0.9677\n",
            "Epoch 49/100\n",
            "199/199 [==============================] - 21s 104ms/step - loss: 0.1529 - accuracy: 0.9688\n",
            "Epoch 50/100\n",
            "199/199 [==============================] - 21s 107ms/step - loss: 0.1467 - accuracy: 0.9705\n",
            "Epoch 51/100\n",
            "199/199 [==============================] - 21s 106ms/step - loss: 0.1376 - accuracy: 0.9707\n",
            "Epoch 52/100\n",
            "199/199 [==============================] - 21s 107ms/step - loss: 0.1373 - accuracy: 0.9707\n",
            "Epoch 53/100\n",
            "199/199 [==============================] - 22s 108ms/step - loss: 0.1346 - accuracy: 0.9694\n",
            "Epoch 54/100\n",
            "199/199 [==============================] - 21s 105ms/step - loss: 0.1262 - accuracy: 0.9708\n",
            "Epoch 55/100\n",
            "199/199 [==============================] - 21s 105ms/step - loss: 0.1212 - accuracy: 0.9704\n",
            "Epoch 56/100\n",
            "199/199 [==============================] - 21s 107ms/step - loss: 0.1262 - accuracy: 0.9694\n",
            "Epoch 57/100\n",
            "199/199 [==============================] - 21s 108ms/step - loss: 0.1141 - accuracy: 0.9716\n",
            "Epoch 58/100\n",
            "199/199 [==============================] - 21s 107ms/step - loss: 0.1254 - accuracy: 0.9699\n",
            "Epoch 59/100\n",
            "199/199 [==============================] - 19s 97ms/step - loss: 0.1229 - accuracy: 0.9697\n",
            "Epoch 60/100\n",
            "199/199 [==============================] - 20s 102ms/step - loss: 0.2148 - accuracy: 0.9527\n",
            "Epoch 61/100\n",
            "199/199 [==============================] - 20s 102ms/step - loss: 0.2470 - accuracy: 0.9513\n",
            "Epoch 62/100\n",
            "199/199 [==============================] - 21s 105ms/step - loss: 0.1458 - accuracy: 0.9697\n",
            "Epoch 63/100\n",
            "199/199 [==============================] - 20s 103ms/step - loss: 0.1204 - accuracy: 0.9711\n",
            "Epoch 64/100\n",
            "199/199 [==============================] - 21s 104ms/step - loss: 0.1110 - accuracy: 0.9702\n",
            "Epoch 65/100\n",
            "199/199 [==============================] - 21s 106ms/step - loss: 0.1052 - accuracy: 0.9710\n",
            "Epoch 66/100\n",
            "199/199 [==============================] - 21s 107ms/step - loss: 0.1008 - accuracy: 0.9699\n",
            "Epoch 67/100\n",
            "199/199 [==============================] - 22s 108ms/step - loss: 0.0978 - accuracy: 0.9711\n",
            "Epoch 68/100\n",
            "199/199 [==============================] - 21s 105ms/step - loss: 0.0973 - accuracy: 0.9710\n",
            "Epoch 69/100\n",
            "199/199 [==============================] - 21s 105ms/step - loss: 0.0941 - accuracy: 0.9710\n",
            "Epoch 70/100\n",
            "199/199 [==============================] - 21s 107ms/step - loss: 0.0921 - accuracy: 0.9724\n",
            "Epoch 71/100\n",
            "199/199 [==============================] - 21s 108ms/step - loss: 0.0911 - accuracy: 0.9715\n",
            "Epoch 72/100\n",
            "199/199 [==============================] - 22s 108ms/step - loss: 0.0911 - accuracy: 0.9715\n",
            "Epoch 73/100\n",
            "199/199 [==============================] - 21s 107ms/step - loss: 0.0874 - accuracy: 0.9721\n",
            "Epoch 74/100\n",
            "199/199 [==============================] - 20s 102ms/step - loss: 0.0858 - accuracy: 0.9726\n",
            "Epoch 75/100\n",
            "199/199 [==============================] - 21s 107ms/step - loss: 0.0884 - accuracy: 0.9711\n",
            "Epoch 76/100\n",
            "199/199 [==============================] - 21s 107ms/step - loss: 0.0848 - accuracy: 0.9724\n",
            "Epoch 77/100\n",
            "199/199 [==============================] - 21s 107ms/step - loss: 0.0861 - accuracy: 0.9718\n",
            "Epoch 78/100\n",
            "199/199 [==============================] - 21s 108ms/step - loss: 0.0850 - accuracy: 0.9713\n",
            "Epoch 79/100\n",
            "199/199 [==============================] - 20s 101ms/step - loss: 0.0820 - accuracy: 0.9719\n",
            "Epoch 80/100\n",
            "199/199 [==============================] - 21s 108ms/step - loss: 0.0835 - accuracy: 0.9710\n",
            "Epoch 81/100\n",
            "199/199 [==============================] - 21s 107ms/step - loss: 0.0838 - accuracy: 0.9705\n",
            "Epoch 82/100\n",
            "199/199 [==============================] - 21s 108ms/step - loss: 0.1417 - accuracy: 0.9585\n",
            "Epoch 83/100\n",
            "199/199 [==============================] - 21s 108ms/step - loss: 0.1566 - accuracy: 0.9579\n",
            "Epoch 84/100\n",
            "199/199 [==============================] - 21s 106ms/step - loss: 0.0942 - accuracy: 0.9700\n",
            "Epoch 85/100\n",
            "199/199 [==============================] - 20s 101ms/step - loss: 0.0827 - accuracy: 0.9708\n",
            "Epoch 86/100\n",
            "199/199 [==============================] - 21s 107ms/step - loss: 0.0800 - accuracy: 0.9726\n",
            "Epoch 87/100\n",
            "199/199 [==============================] - 21s 107ms/step - loss: 0.0788 - accuracy: 0.9716\n",
            "Epoch 88/100\n",
            "199/199 [==============================] - 21s 107ms/step - loss: 0.0796 - accuracy: 0.9710\n",
            "Epoch 89/100\n",
            "199/199 [==============================] - 21s 107ms/step - loss: 0.0785 - accuracy: 0.9718\n",
            "Epoch 90/100\n",
            "199/199 [==============================] - 21s 103ms/step - loss: 0.0776 - accuracy: 0.9733\n",
            "Epoch 91/100\n",
            "199/199 [==============================] - 21s 107ms/step - loss: 0.0769 - accuracy: 0.9729\n",
            "Epoch 92/100\n",
            "199/199 [==============================] - 21s 108ms/step - loss: 0.0773 - accuracy: 0.9718\n",
            "Epoch 93/100\n",
            "199/199 [==============================] - 21s 107ms/step - loss: 0.0782 - accuracy: 0.9715\n",
            "Epoch 94/100\n",
            "199/199 [==============================] - 22s 109ms/step - loss: 0.0781 - accuracy: 0.9726\n",
            "Epoch 95/100\n",
            "199/199 [==============================] - 21s 106ms/step - loss: 0.0779 - accuracy: 0.9716\n",
            "Epoch 96/100\n",
            "199/199 [==============================] - 22s 107ms/step - loss: 0.0761 - accuracy: 0.9716\n",
            "Epoch 97/100\n",
            "199/199 [==============================] - 22s 109ms/step - loss: 0.0768 - accuracy: 0.9738\n",
            "Epoch 98/100\n",
            "199/199 [==============================] - 22s 109ms/step - loss: 0.0768 - accuracy: 0.9721\n",
            "Epoch 99/100\n",
            "199/199 [==============================] - 21s 108ms/step - loss: 0.0774 - accuracy: 0.9729\n",
            "Epoch 100/100\n",
            "199/199 [==============================] - 22s 109ms/step - loss: 0.0754 - accuracy: 0.9715\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7fe9ffe1df90>"
            ]
          },
          "metadata": {},
          "execution_count": null
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function for Generating text with a Trained Language Model"
      ],
      "metadata": {
        "id": "XZZBT7BpASfW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(prompt, model, tokenizer, max_sequence_len, num_words=50):\n",
        "    seed_text = prompt.lower()\n",
        "    for _ in range(num_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "        predicted_probs = model.predict(token_list, verbose=0)[0]\n",
        "        predicted_index = np.argmax(predicted_probs)\n",
        "        output_word = \"\"\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted_index:\n",
        "                output_word = word\n",
        "                break\n",
        "        seed_text += \" \" + output_word\n",
        "    print(seed_text.capitalize())"
      ],
      "metadata": {
        "id": "gqMf5PnaI07m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interactive Text Generation with Trained Model"
      ],
      "metadata": {
        "id": "PTo1es8iAYq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    prompt = input(\"Enter a prompt for writing (type 'exit' to quit):\\n\")\n",
        "    if prompt.lower() == 'exit':\n",
        "        print(\"Goodbye!\")\n",
        "        break\n",
        "    print(\"Here's your writing:\")\n",
        "    generate_text(prompt, model, tokenizer, max_sequence_len)\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f76ShByJeKLN",
        "outputId": "c11191e9-d3fe-4b0d-a798-74c2c8f91694"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a prompt for writing (type 'exit' to quit):\n",
            "A beautiful sunset\n",
            "Here's your writing:\n",
            "A beautiful sunset sunset paint the sky in shades of orange and gold with clouds ablaze and the horizon ablaze with color i felt a sense of gratitude for the beauty of the world and the gift of another day day day patterns of another day day day day day day day day\n",
            "\n",
            "\n",
            "Enter a prompt for writing (type 'exit' to quit):\n",
            "About an adventurous journey\n",
            "Here's your writing:\n",
            "About an adventurous journey through the shimmering portal i found myself transported to a world of wonder and enchantment twisting where me and fantasy intertwined reality i had entered a world untouched by man i had been transported to a paradise on earth wonder and wonder to the embrace of nature and and possible\n",
            "\n",
            "\n",
            "Enter a prompt for writing (type 'exit' to quit):\n",
            "Exploration\n",
            "Here's your writing:\n",
            "Exploration the tranquility of the forest i embarked on a peaceful journey guided by the whispers of the wind and lurked in the rhythm of the ocean and lost in the whirlpool of emotion long lost at time one with a untamed beauty of the sea kingdom the moment and away\n",
            "\n",
            "\n",
            "Enter a prompt for writing (type 'exit' to quit):\n",
            "exit\n",
            "Goodbye!\n"
          ]
        }
      ]
    }
  ]
}
